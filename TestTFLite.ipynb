{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "use_TPU  = False\n",
    "from tflite_runtime.interpreter import Interpreter\n",
    "from myprotos import string_int_label_map_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "#讀取LabelMap Function\n",
    "def LoadLabelmap(LabelMapPath , UseDisplayName = True):\n",
    "    with open(LabelMapPath) as f:\n",
    "        Labelmap_String = f.read()\n",
    "    LabelMap = string_int_label_map_pb2.StringIntLabelMap()\n",
    "    text_format.Merge(Labelmap_String, LabelMap)\n",
    "    LabelmapDict = {}\n",
    "    for item in LabelMap.item:\n",
    "        if (UseDisplayName == True):\n",
    "            LabelmapDict[item.id] = item.display_name \n",
    "        else:\n",
    "            LabelmapDict[item.id] = item.name \n",
    "    return LabelmapDict\n",
    "\n",
    "#====讀取模型====\n",
    "if use_TPU:\n",
    "    from tflite_runtime.interpreter import load_delegate\n",
    "    interpreter = Interpreter(model_path=r'tfliteModel/ForClass_SSD_ModileNetV2Edgetpu_COCO/detect_edgetpu.tflite',experimental_delegates=[load_delegate('libedgetpu.so.1.0')])\n",
    "else:\n",
    "    interpreter = Interpreter(model_path=r'tfliteModel/ForClass_SSD_ModileNetV2Quantized_COCO/detect.tflite')\n",
    "\n",
    "interpreter.allocate_tensors() #讀取配置模型\n",
    "Input_Info = interpreter.get_input_details() #取得輸入節點資訊，取得輸入解析度與輸入節點的序號\n",
    "Output_Info = interpreter.get_output_details() #取得輸出節點資訊\n",
    "\n",
    "#====讀取labelmap====\n",
    "LabelmapDict = LoadLabelmap(r'tfliteModel/ForClass_SSD_ModileNetV2Quantized_COCO/labelmap.pbtxt',False)\n",
    "\n",
    "#====讀取圖型====\n",
    "MyCam = cv2.VideoCapture('ValidateVideo.mp4') #使用影片物件檢測，改成Mcv2.VideoCapture(0)可以使用攝影機\n",
    "while(MyCam.isOpened()):\n",
    "    ret, cvimg = MyCam.read()\n",
    "    if (ret == False): #影片讀取結束或是讀取錯誤，所以讀取失敗\n",
    "        break\n",
    "    cvimgRGB = cv2.cvtColor(cvimg, cv2.COLOR_BGR2RGB) #OpenCV顏色轉換成RGB顏色順序\n",
    "    \n",
    "    #====處理圖型 成為適合tensorflw格式====\n",
    "    #因為tflite只能輸入固定大小的圖片，所以必須將輸入的圖片縮放成符合的尺寸\n",
    "    cvimgRGB_Resized = cv2.resize(cvimgRGB, (Input_Info[0]['shape'][2], Input_Info[0]['shape'][1])) \n",
    "    Input_data = np.expand_dims(cvimgRGB_Resized, axis=0) #將原本的3維陣列 [寬,高,RGB]  轉成4維度的陣列[第幾張圖片, 寬，高，RGB]\n",
    "    if (Input_Info[0]['dtype'] == np.float32): #判斷輸入的型態，是否需要將圖型正規劃(將數值由0~255轉換到-1~1)\n",
    "        Input_data = (np.float32(Input_data) - 127.5) / 127.5 #要將輸入資料0-255的顏色資訊轉成 -1 ~ 1 的正規劃數值\n",
    "    \n",
    "    #====使用模型推理====\n",
    "    StartTime = time.time()\n",
    "    interpreter.set_tensor(Input_Info[0]['index'],Input_data) #設定輸入\n",
    "    interpreter.invoke() #執行模型\n",
    "\n",
    "    #====取出結果====\n",
    "    detection_boxes    =interpreter.get_tensor(Output_Info[0]['index'])[0] # 輸出檢測框   [第0張圖片]\n",
    "    detection_classes  =interpreter.get_tensor(Output_Info[1]['index'])[0] # 輸出檢測類別 [第0張圖片]\n",
    "    detection_scores   =interpreter.get_tensor(Output_Info[2]['index'])[0] # 輸出檢測信信指數 [第0張圖片]\n",
    "    num_detections     =interpreter.get_tensor(Output_Info[3]['index'])[0]  # 輸出檢測數量 [第0張圖片]\n",
    "\n",
    "    #====繪出結果====\n",
    "    for i in range(int(num_detections)):\n",
    "        ClassID = int(detection_classes[i]+1) #ClassID由0開始，但是labelmap由1開始\n",
    "        Score = float(detection_scores[i])\n",
    "        if (Score > 0.5):\n",
    "            y1 = int(detection_boxes[i][0] * cvimgRGB.shape[0])\n",
    "            x1 = int(detection_boxes[i][1] * cvimgRGB.shape[1])\n",
    "            y2 = int(detection_boxes[i][2] * cvimgRGB.shape[0])\n",
    "            x2 = int(detection_boxes[i][3] * cvimgRGB.shape[1])\n",
    "            cv2.rectangle(cvimg,(x1,y1),(x2,y2),(0,255,0),thickness=3)\n",
    "            \n",
    "            info = 'Class:{} Score:{}'.format(LabelmapDict[ClassID], round(Score,2))   \n",
    "            #cv2.putText(目標圖片,   文字,   (x,y),字型             ,字體大小縮放,顏色(B,G,R),字體粗細))\n",
    "            cv2.putText(cvimg, info,(x1+5,y1+30), cv2.FONT_HERSHEY_COMPLEX,1, (255, 255, 0), 2)\n",
    "    EndTime = time.time()\n",
    "    Dtime = EndTime - StartTime\n",
    "    cv2.putText(cvimg, str(int(Dtime*1000)) + 'ms', (0 + 5, 0 + 30), cv2.FONT_HERSHEY_COMPLEX,1, (0, 255, 255), 1)\n",
    "    cv2.imshow('Hello',cvimg) \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "MyCam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
